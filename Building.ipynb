{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReferenceAllele</th>\n",
       "      <th>AlternateAllele</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stop</th>\n",
       "      <th>GeneSymbol</th>\n",
       "      <th>ClinicalSignificance</th>\n",
       "      <th>PhenotypeList</th>\n",
       "      <th>Type</th>\n",
       "      <th>Assembly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>7</td>\n",
       "      <td>4820844</td>\n",
       "      <td>4820847</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>Pathogenic/Likely pathogenic</td>\n",
       "      <td>Hereditary spastic paraplegia 48|Macular dystr...</td>\n",
       "      <td>Indel</td>\n",
       "      <td>GRCh37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>7</td>\n",
       "      <td>4781213</td>\n",
       "      <td>4781216</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>Pathogenic/Likely pathogenic</td>\n",
       "      <td>Hereditary spastic paraplegia 48|Macular dystr...</td>\n",
       "      <td>Indel</td>\n",
       "      <td>GRCh38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>7</td>\n",
       "      <td>4827361</td>\n",
       "      <td>4827374</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>Hereditary spastic paraplegia 48</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>GRCh37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>7</td>\n",
       "      <td>4787730</td>\n",
       "      <td>4787743</td>\n",
       "      <td>AP5Z1</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>Hereditary spastic paraplegia 48</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>GRCh38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>15</td>\n",
       "      <td>85342440</td>\n",
       "      <td>85342440</td>\n",
       "      <td>ZNF592</td>\n",
       "      <td>Uncertain significance</td>\n",
       "      <td>Galloway-Mowat syndrome 1</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>GRCh37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ReferenceAllele AlternateAllele Chromosome     Start      Stop GeneSymbol  \\\n",
       "0              na              na          7   4820844   4820847      AP5Z1   \n",
       "1              na              na          7   4781213   4781216      AP5Z1   \n",
       "2              na              na          7   4827361   4827374      AP5Z1   \n",
       "3              na              na          7   4787730   4787743      AP5Z1   \n",
       "4              na              na         15  85342440  85342440     ZNF592   \n",
       "\n",
       "           ClinicalSignificance  \\\n",
       "0  Pathogenic/Likely pathogenic   \n",
       "1  Pathogenic/Likely pathogenic   \n",
       "2                    Pathogenic   \n",
       "3                    Pathogenic   \n",
       "4        Uncertain significance   \n",
       "\n",
       "                                       PhenotypeList  \\\n",
       "0  Hereditary spastic paraplegia 48|Macular dystr...   \n",
       "1  Hereditary spastic paraplegia 48|Macular dystr...   \n",
       "2                   Hereditary spastic paraplegia 48   \n",
       "3                   Hereditary spastic paraplegia 48   \n",
       "4                          Galloway-Mowat syndrome 1   \n",
       "\n",
       "                        Type Assembly  \n",
       "0                      Indel   GRCh37  \n",
       "1                      Indel   GRCh38  \n",
       "2                   Deletion   GRCh37  \n",
       "3                   Deletion   GRCh38  \n",
       "4  single nucleotide variant   GRCh37  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Load your data\n",
    "csv_file = \"variant_sample_25k.csv\"\n",
    "assert os.path.exists(csv_file), f\"CSV not found: {csv_file}\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Drop duplicates and obvious bad rows (defensive)\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=[\"ReferenceAllele\",\"AlternateAllele\",\"Chromosome\",\"Start\",\"GeneSymbol\",\"ClinicalSignificance\"])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Normalize whitespace\n",
    "for col in [\"ReferenceAllele\",\"AlternateAllele\",\"GeneSymbol\",\"ClinicalSignificance\",\"PhenotypeList\",\"Type\",\"Assembly\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClinSigClass\n",
       "Pathogenic           15792\n",
       "Likely pathogenic     4656\n",
       "VUS                   1345\n",
       "Benign                 511\n",
       "Likely benign          378\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Map ClinicalSignificance to a canonical single class\n",
    "# You can adjust this mapping to fit your modeling goal.\n",
    "canonical_map = {\n",
    "    \"Pathogenic\": \"Pathogenic\",\n",
    "    \"Likely pathogenic\": \"Likely pathogenic\",\n",
    "    \"Benign\": \"Benign\",\n",
    "    \"Likely benign\": \"Likely benign\",\n",
    "    \"Uncertain significance\": \"VUS\",  # VUS = Variant of Uncertain Significance\n",
    "}\n",
    "\n",
    "def normalize_clinsig(x: str) -> str:\n",
    "    s = x.lower()\n",
    "    # Prioritize specific terms; order matters\n",
    "    if \"pathogenic\" in s and \"likely\" not in s and \"conflict\" not in s:\n",
    "        return \"Pathogenic\"\n",
    "    if \"likely pathogenic\" in s:\n",
    "        return \"Likely pathogenic\"\n",
    "    if \"benign\" in s and \"likely\" not in s and \"conflict\" not in s:\n",
    "        return \"Benign\"\n",
    "    if \"likely benign\" in s:\n",
    "        return \"Likely benign\"\n",
    "    if \"uncertain\" in s:\n",
    "        return \"VUS\"\n",
    "    # collapse everything else into \"Other\" to avoid label explosion\n",
    "    return \"Other\"\n",
    "\n",
    "df[\"ClinSigClass\"] = df[\"ClinicalSignificance\"].apply(normalize_clinsig)\n",
    "\n",
    "# Option: drop \"Other\" to simplify; or keep it as a class\n",
    "keep_classes = [\"Pathogenic\",\"Likely pathogenic\",\"Benign\",\"Likely benign\",\"VUS\"]\n",
    "df = df[df[\"ClinSigClass\"].isin(keep_classes)].reset_index(drop=True)\n",
    "\n",
    "df[\"ClinSigClass\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   ChromInt     Start      Stop  ref_len  ref_count_A  ref_count_C  \\\n",
       " 0         7   4820844   4820847        2            1            0   \n",
       " 1         7   4781213   4781216        2            1            0   \n",
       " 2         7   4827361   4827374        2            1            0   \n",
       " 3         7   4787730   4787743        2            1            0   \n",
       " 4        15  85342440  85342440        2            1            0   \n",
       " \n",
       "    ref_count_G  ref_count_T  alt_len  alt_count_A  alt_count_C  alt_count_G  \\\n",
       " 0            0            0        2            1            0            0   \n",
       " 1            0            0        2            1            0            0   \n",
       " 2            0            0        2            1            0            0   \n",
       " 3            0            0        2            1            0            0   \n",
       " 4            0            0        2            1            0            0   \n",
       " \n",
       "    alt_count_T                       Type Assembly GeneSymbol_Limited  \n",
       " 0            0                      Indel   GRCh37              AP5Z1  \n",
       " 1            0                      Indel   GRCh38              AP5Z1  \n",
       " 2            0                   Deletion   GRCh37              AP5Z1  \n",
       " 3            0                   Deletion   GRCh38              AP5Z1  \n",
       " 4            0  single nucleotide variant   GRCh37             ZNF592  ,\n",
       " 0    Likely pathogenic\n",
       " 1    Likely pathogenic\n",
       " 2           Pathogenic\n",
       " 3           Pathogenic\n",
       " 4                  VUS\n",
       " Name: ClinSigClass, dtype: object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Simple featurization of alleles\n",
    "def allele_features(series):\n",
    "    # length and nucleotide composition\n",
    "    out = pd.DataFrame({\n",
    "        \"len\": series.str.len().fillna(0).astype(int),\n",
    "        \"count_A\": series.str.upper().str.count(\"A\").fillna(0).astype(int),\n",
    "        \"count_C\": series.str.upper().str.count(\"C\").fillna(0).astype(int),\n",
    "        \"count_G\": series.str.upper().str.count(\"G\").fillna(0).astype(int),\n",
    "        \"count_T\": series.str.upper().str.count(\"T\").fillna(0).astype(int),\n",
    "    })\n",
    "    return out\n",
    "\n",
    "ref_feats = allele_features(df[\"ReferenceAllele\"]).add_prefix(\"ref_\")\n",
    "alt_feats = allele_features(df[\"AlternateAllele\"]).add_prefix(\"alt_\")\n",
    "\n",
    "# Make Chromosome numeric-like: X,Y,MT -> 23,24,25\n",
    "def chr_to_int(x):\n",
    "    s = str(x).strip()\n",
    "    if s in [\"X\",\"x\"]: return 23\n",
    "    if s in [\"Y\",\"y\"]: return 24\n",
    "    if s.upper() in [\"MT\",\"M\",\"MITO\",\"CHRMT\"]: return 25\n",
    "    try:\n",
    "        v = int(s)\n",
    "        return v if 1 <= v <= 22 else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "df[\"ChromInt\"] = df[\"Chromosome\"].apply(chr_to_int).astype(int)\n",
    "\n",
    "# Start/Stop numeric\n",
    "df[\"Start\"] = pd.to_numeric(df[\"Start\"], errors=\"coerce\")\n",
    "if \"Stop\" in df.columns:\n",
    "    df[\"Stop\"] = pd.to_numeric(df[\"Stop\"], errors=\"coerce\")\n",
    "else:\n",
    "    df[\"Stop\"] = df[\"Start\"]  # fallback if Stop absent in some rows\n",
    "\n",
    "# GeneSymbol: cap cardinality\n",
    "top_k = 3000  # adjust based on memory/training time\n",
    "top_genes = df[\"GeneSymbol\"].value_counts().nlargest(top_k).index\n",
    "df[\"GeneSymbol_Limited\"] = np.where(df[\"GeneSymbol\"].isin(top_genes), df[\"GeneSymbol\"], \"OTHER\")\n",
    "\n",
    "# Select raw columns for preprocessing\n",
    "num_cols = [\n",
    "    \"ChromInt\",\"Start\",\"Stop\",\n",
    "    \"ref_len\",\"ref_count_A\",\"ref_count_C\",\"ref_count_G\",\"ref_count_T\",\n",
    "    \"alt_len\",\"alt_count_A\",\"alt_count_C\",\"alt_count_G\",\"alt_count_T\"\n",
    "]\n",
    "cat_cols = []\n",
    "if \"Type\" in df.columns: cat_cols.append(\"Type\")\n",
    "if \"Assembly\" in df.columns: cat_cols.append(\"Assembly\")\n",
    "cat_cols.append(\"GeneSymbol_Limited\")\n",
    "\n",
    "# Assemble feature frame\n",
    "X_num = pd.concat([ref_feats, alt_feats], axis=1)\n",
    "X_base = pd.concat([df[[\"ChromInt\",\"Start\",\"Stop\"]], X_num], axis=1)\n",
    "X_cat = df[cat_cols].copy()\n",
    "\n",
    "X = pd.concat([X_base, X_cat], axis=1)\n",
    "y = df[\"ClinSigClass\"].copy()\n",
    "\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ClinSigClass\n",
       " Pathogenic           0.696225\n",
       " Likely pathogenic    0.205291\n",
       " VUS                  0.059300\n",
       " Benign               0.022541\n",
       " Likely benign        0.016644\n",
       " Name: proportion, dtype: float64,\n",
       " ClinSigClass\n",
       " Pathogenic           0.696275\n",
       " Likely pathogenic    0.205202\n",
       " VUS                  0.059290\n",
       " Benign               0.022482\n",
       " Likely benign        0.016751\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "y_train.value_counts(normalize=True), y_val.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18145, 1859), (4537, 1859))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) Preprocessing with ColumnTransformer\n",
    "numeric_features = num_cols\n",
    "categorical_features = cat_cols\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True))\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", dtype=np.float32)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on train, transform train/val\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "X_train_proc = preprocessor.transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "X_train_proc.shape, X_val_proc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor_clinsig.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessor, \"preprocessor_clinsig.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benign', 'Likely benign', 'Likely pathogenic', 'Pathogenic', 'VUS']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9) Label encoding\n",
    "label_encoder = OrdinalEncoder(dtype=np.int32)\n",
    "y_train_enc = label_encoder.fit_transform(y_train.to_frame()).astype(np.int32).ravel()\n",
    "y_val_enc = label_encoder.transform(y_val.to_frame()).astype(np.int32).ravel()\n",
    "\n",
    "classes_ = label_encoder.categories_[0].tolist()\n",
    "num_classes = len(classes_)\n",
    "classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 8.87286063569682,\n",
       " 1: 12.016556291390728,\n",
       " 2: 0.9742281879194631,\n",
       " 3: 0.2872635161877622,\n",
       " 4: 3.3726765799256504}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10) Class weights to mitigate imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.arange(num_classes),\n",
    "    y=y_train_enc\n",
    ")\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "class_weight_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1859</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">952,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1859\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m952,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,773</span> (4.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,120,773\u001b[0m (4.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,118,981</span> (4.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,118,981\u001b[0m (4.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11) Build model\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "input_dim = X_train_proc.shape[1]\n",
    "\n",
    "def build_mlp(input_dim, num_classes, dropout=0.2):\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_mlp(input_dim, num_classes, dropout=0.3)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.2049 - loss: 2.2547 - val_accuracy: 0.0595 - val_loss: 1.6563 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.2755 - loss: 1.7344 - val_accuracy: 0.0719 - val_loss: 1.6746 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3243 - loss: 1.4429 - val_accuracy: 0.0679 - val_loss: 1.6876 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3701 - loss: 1.2634 - val_accuracy: 0.0961 - val_loss: 1.5789 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4146 - loss: 1.0808 - val_accuracy: 0.1087 - val_loss: 1.5746 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4605 - loss: 0.9764 - val_accuracy: 0.1913 - val_loss: 1.5058 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4998 - loss: 0.8869 - val_accuracy: 0.2061 - val_loss: 1.4749 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5251 - loss: 0.8556 - val_accuracy: 0.2804 - val_loss: 1.3910 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5445 - loss: 0.8305 - val_accuracy: 0.3017 - val_loss: 1.3708 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5617 - loss: 0.7851 - val_accuracy: 0.3432 - val_loss: 1.3417 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5709 - loss: 0.7407 - val_accuracy: 0.3892 - val_loss: 1.2893 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5841 - loss: 0.7515 - val_accuracy: 0.4201 - val_loss: 1.2315 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5845 - loss: 0.7227 - val_accuracy: 0.4459 - val_loss: 1.1627 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5876 - loss: 0.6998 - val_accuracy: 0.4529 - val_loss: 1.1689 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5952 - loss: 0.6790 - val_accuracy: 0.4600 - val_loss: 1.1369 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6020 - loss: 0.6530 - val_accuracy: 0.4651 - val_loss: 1.1149 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5985 - loss: 0.6485 - val_accuracy: 0.4706 - val_loss: 1.0811 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6070 - loss: 0.6474 - val_accuracy: 0.4915 - val_loss: 1.0397 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6085 - loss: 0.6264 - val_accuracy: 0.4849 - val_loss: 1.0531 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6133 - loss: 0.6369 - val_accuracy: 0.4814 - val_loss: 1.0528 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6173 - loss: 0.6016 - val_accuracy: 0.4977 - val_loss: 1.0184 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6229 - loss: 0.5937 - val_accuracy: 0.5047 - val_loss: 1.0110 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6262 - loss: 0.5975 - val_accuracy: 0.5080 - val_loss: 0.9963 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6203 - loss: 0.5991 - val_accuracy: 0.5010 - val_loss: 0.9906 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6242 - loss: 0.5904 - val_accuracy: 0.4988 - val_loss: 1.0133 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6221 - loss: 0.5874 - val_accuracy: 0.5058 - val_loss: 0.9993 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6281 - loss: 0.5723 - val_accuracy: 0.4999 - val_loss: 1.0017 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6331 - loss: 0.5702 - val_accuracy: 0.4889 - val_loss: 1.0162 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# 12) Train\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train_enc,\n",
    "    validation_data=(X_val_proc, y_val_enc),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Accuracy: 0.5080449636323562\n",
      "\n",
      "Classification report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           Benign       0.33      0.51      0.40       102\n",
      "    Likely benign       0.09      0.37      0.14        76\n",
      "Likely pathogenic       0.36      0.61      0.45       931\n",
      "       Pathogenic       0.88      0.48      0.62      3159\n",
      "              VUS       0.18      0.51      0.26       269\n",
      "\n",
      "         accuracy                           0.51      4537\n",
      "        macro avg       0.37      0.50      0.38      4537\n",
      "     weighted avg       0.71      0.51      0.55      4537\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  52    5   15    3   27]\n",
      " [  10   28   15    6   17]\n",
      " [  22   48  566  153  142]\n",
      " [  66  215  913 1522  443]\n",
      " [   9   28   59   36  137]]\n"
     ]
    }
   ],
   "source": [
    "# 13) Evaluation\n",
    "val_probs = model.predict(X_val_proc, batch_size=1024)\n",
    "val_pred = np.argmax(val_probs, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", (val_pred == y_val_enc).mean())\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val_enc, val_pred, target_names=classes_))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_val_enc, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=clinsig_mlp. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(clinsig_mlp, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kaila\\dna\\Building.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kaila/dna/Building.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     pre \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mpreprocessor_clinsig.joblib\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kaila/dna/Building.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pre\u001b[39m.\u001b[39mtransform(X_new)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kaila/dna/Building.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m\"\u001b[39;49m\u001b[39mclinsig_mlp\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kaila/dna/Building.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlabel_encoder_classes.json\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kaila/dna/Building.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     classes_loaded \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\Users\\Kaila\\.pyenv\\pyenv-win\\versions\\3.10.0\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile not found: filepath=\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mzip file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile format not supported: filepath=\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that the legacy SavedModel format is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minference-only layer in Keras 3, use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`keras.layers.TFSMLayer(\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m, call_endpoint=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mserving_default\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(note that your `call_endpoint` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmight have a different name).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=clinsig_mlp. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(clinsig_mlp, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "# 15) Inference function\n",
    "import joblib\n",
    "def preprocess_new(df_new: pd.DataFrame):\n",
    "    # reproduce feature engineering\n",
    "    ref_feats = allele_features(df_new[\"ReferenceAllele\"]).add_prefix(\"ref_\")\n",
    "    alt_feats = allele_features(df_new[\"AlternateAllele\"]).add_prefix(\"alt_\")\n",
    "    df_new[\"ChromInt\"] = df_new[\"Chromosome\"].apply(chr_to_int).astype(int)\n",
    "    df_new[\"Start\"] = pd.to_numeric(df_new[\"Start\"], errors=\"coerce\")\n",
    "    if \"Stop\" not in df_new.columns:\n",
    "        df_new[\"Stop\"] = df_new[\"Start\"]\n",
    "    else:\n",
    "        df_new[\"Stop\"] = pd.to_numeric(df_new[\"Stop\"], errors=\"coerce\")\n",
    "\n",
    "    # gene bucketing: unseen -> OTHER\n",
    "    df_new[\"GeneSymbol_Limited\"] = np.where(df_new[\"GeneSymbol\"].isin(top_genes), df_new[\"GeneSymbol\"], \"OTHER\")\n",
    "\n",
    "    X_num = pd.concat([ref_feats, alt_feats], axis=1)\n",
    "    X_base = pd.concat([df_new[[\"ChromInt\",\"Start\",\"Stop\"]], X_num], axis=1)\n",
    "    X_cat = df_new[cat_cols].copy()\n",
    "\n",
    "    X_new = pd.concat([X_base, X_cat], axis=1)\n",
    "    pre = joblib.load(\"preprocessor_clinsig.joblib\")\n",
    "    return pre.transform(X_new)\n",
    "\n",
    "loaded_model = keras.models.load_model(\"clinsig_mlp\")\n",
    "with open(\"label_encoder_classes.json\") as f:\n",
    "    classes_loaded = json.load(f)\n",
    "\n",
    "# Example (make sure columns exist)\n",
    "# df_example = df.iloc[:5].copy()\n",
    "# X_example = preprocess_new(df_example)\n",
    "# preds = loaded_model.predict(X_example)\n",
    "# pred_labels = np.array(classes_loaded)[np.argmax(preds, axis=1)]\n",
    "# pred_labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
